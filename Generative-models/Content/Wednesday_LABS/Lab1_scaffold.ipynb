{"cells":[{"cell_type":"markdown","source":["<a href=\"https://drive.google.com/file/d/1LavEDKL8j1XDyVLBJ8JyTABinqqIQweV/view?usp=sharing\" target=\"_blank\" >\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"],"metadata":{"id":"igdZWOTjEK_z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNfu_5tYEH6f"},"outputs":[],"source":["import warnings\n","# Suppress all warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kn3rrtPIEH6h","outputId":"6dcb5b19-c6fd-40b6-c93d-d2c4cb95465c"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-21 16:10:38.310291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-21 16:10:38.320360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-21 16:10:38.323441: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-21 16:10:38.331677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-21 16:10:38.863308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["#Importing libraries\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from IPython.display import HTML\n","from matplotlib.animation import FuncAnimation\n","from keras.layers import LeakyReLU\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbrqtmbOEH6i"},"outputs":[],"source":["# Defining necessary parameters\n","batch_size = 512\n","latent_dim = 8"]},{"cell_type":"markdown","metadata":{"id":"V8ULMravEH6i"},"source":["## Define a Discriminator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLy5olNsEH6i"},"outputs":[],"source":["# Build a discriminator neural network\n","def build_discriminator(dim):\n","  model = Sequential()\n","  for _ in range(2):\n","    model.add(____) # Dense layer with 64 neurons and activation = LeakyReLU\n","  model.add(Dense(___, activation=____))\n","  return ____"]},{"cell_type":"markdown","metadata":{"id":"PIym2NXbEH6j"},"source":["## Define a Generator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0dTyQjqEH6j"},"outputs":[],"source":["# Build a generator neural network\n","def build_generator(latent_dim, output_dim):\n","  model = Sequential()\n","  for _ in range(4):\n","    model.add(____) # Dense layer with 16 neurons and activation = LeakyReLU\n","  model.add(Dense(output_dim))\n","  return ____"]},{"cell_type":"markdown","metadata":{"id":"OMHGqgT8EH6j"},"source":["## Defining and Training the GAN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnK-SsbWEH6j"},"outputs":[],"source":["# Generate random uniform noise to input to the generator\n","def generate_input_noise(batch_size, latent_dim):\n","    return ____"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j43qBWL-EH6j"},"outputs":[],"source":["#  Generate real data from a normal distribution to train discriminator\n","def get_real_data(n_samples,output_dim):\n","    ____ # Set the tensorflow random seed as 109\n","    return ____"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iw38RxiyEH6k"},"outputs":[],"source":["# Build the GAN\n","g_model = build_generator(____, ___)\n","d_model = build_discriminator(___)"]},{"cell_type":"markdown","metadata":{"id":"pdzzsJuTEH6k"},"source":["## Losses or Optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tEztqbUxEH6k"},"outputs":[],"source":["bce_loss = tf.keras.losses.BinaryCrossentropy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"flt--EwYEH6k"},"outputs":[],"source":["# Discriminator Loss\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = bce_loss(tf.ones_like(real_output), real_output)\n","    fake_loss = bce_loss(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRFq5TOqEH6k"},"outputs":[],"source":["def generator_loss(d_predictions):\n","    return bce_loss(tf.ones_like(d_predictions), d_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3Ry8NoEEH6k"},"outputs":[],"source":["d_optimizer = ____ # Adam optimizer with learning rate = 0.0001\n","g_optimizer = ____ # Adam optimizer with learning rate = 0.006"]},{"cell_type":"markdown","metadata":{"id":"plrz3nK-EH6k"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"r34t8K_6EH6k"},"source":["Define your training loop by iterating through the number of epochs and the batches of real data generated before.\n","\n","Remember, the training loop begins with generator receiving 100-D noise as input. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."]},{"cell_type":"markdown","metadata":{"id":"vqeISchbEH6k"},"source":["Define `train_step` function that trains the generator and discriminator over a batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EZWWLhtEH6k"},"outputs":[],"source":["# Compiles the train_step function into a callable TensorFlow graph\n","# Also speeds up the training time\n","@tf.function\n","def train_step():\n","\n","    real_images = get_real_data(batch_size // 2, 1)\n","    generated_images = g_model(generate_input_noise(batch_size // 2, latent_dim))\n","\n","    # Train the discriminator.\n","    with tf.GradientTape() as tape:\n","        pred_fake = d_model(generated_images)\n","        pred_real = d_model(real_images)\n","\n","        d_loss = discriminator_loss(pred_real, pred_fake)\n","\n","    grads = tape.gradient(d_loss, d_model.trainable_variables)\n","    d_optimizer.apply_gradients(zip(grads, d_model.trainable_variables))\n","\n","    #-----------------------------------------------------------------#\n","\n","    # Sample random points in the latent space.\n","    random_latent_vectors = generate_input_noise(batch_size, latent_dim)\n","\n","    # Train the generator (note that we should *not* update the weights\n","    # of the discriminator)!\n","    with tf.GradientTape() as tape:\n","        fake_images = g_model(random_latent_vectors)\n","        predictions = d_model(fake_images)\n","        g_loss = generator_loss(predictions)\n","\n","    grads = tape.gradient(g_loss, g_model.trainable_variables)\n","    g_optimizer.apply_gradients(zip(grads, g_model.trainable_variables))\n","\n","    return d_loss, g_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["91860d82d7e34fa7b2815dbb96249767"]},"id":"oDWUC_nbEH6k","outputId":"4d55a026-da0c-4b93-b72d-d68e686f2574"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91860d82d7e34fa7b2815dbb96249767","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["D_loss = []\n","G_loss = []\n","G_predict=[]\n","epochs = 1000\n","\n","for epoch in tqdm(range(epochs)):\n","    tf.random.set_seed(109+epoch)\n","    d_loss, g_loss = _____\n","    D_loss.append(____)\n","    G_loss.append(____)\n","\n","    test_noise = generate_input_noise(10000, latent_dim)\n","    fake_samples = g_model.predict(____)\n","    G_predict.append(____)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7P-F0WjEH6l"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n","plt.close(fig)\n","def animate(i):\n","  ax[1].cla()\n","  # Plot loss and accuracy\n","  ax[0].plot(np.arange(4*i), G_loss[0:4*i],label='G loss',c='darkred',zorder=50,alpha=0.8)\n","  ax[0].plot(np.arange(4*i), D_loss[0:4*i],label='D loss',c='darkblue',zorder=55,alpha=0.8)\n","  ax[0].set_xlim(-5, epochs+5)\n","  ax[0].set_ylim(-0.05, 1.55)\n","  ax[0].set_xlabel('Epoch')\n","\n","  #Plot distributions\n","  x_vals = np.linspace(-3, 3, 301)\n","  y_vals = stats.norm(0,1).pdf(x_vals)\n","  ax[1].plot(x_vals, y_vals, color='blue', label='real')\n","  ax[1].fill_between(x_vals, np.zeros(len(x_vals)), y_vals, color='blue', alpha=0.6)\n","  a = sns.kdeplot(G_predict[4*i].flatten(), color='red', alpha=0.6, label='GAN', ax=ax[1], shade=True)\n","  ax[1].set_xlim(-3, 3)\n","  ax[1].set_ylim(0, 0.82)\n","  ax[1].set_xlabel('Sample Space')\n","  ax[1].set_ylabel('Probability Density')\n","\n","simulation = FuncAnimation(fig, animate, frames=epochs//4, interval=100, repeat=True)\n","HTML(simulation.to_html5_video())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYgEhNjQEH6l"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}